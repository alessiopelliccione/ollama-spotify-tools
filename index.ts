import { Ollama } from 'ollama'
import 'dotenv/config';

const ollama = new Ollama({
    host: 'https://ollama.com',
    headers: { Authorization: 'Bearer ' + process.env.OLLAMA_API_KEY },
})

async function main() {
    const response = await ollama.chat({
        model: 'gpt-oss:120b',
        messages: [{ role: 'user', content: 'Explain quantum computing' }],
        stream: true,
    })

    for await (const part of response) {
        process.stdout.write(part.message.content)
    }
}

main().catch((error) => {
    console.error('Failed to run chat example:', error)
    process.exit(1)
})
